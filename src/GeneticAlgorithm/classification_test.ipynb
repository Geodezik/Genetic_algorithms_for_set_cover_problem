{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from itertools import product\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thresholds(df):\n",
    "    threshs = []\n",
    "    threshs_raveled = []\n",
    "    cur_neg = -1\n",
    "    for i in range(df.shape[1] - 1):\n",
    "        df_sorted = df.sort_values(by=i).reset_index(drop='index')\n",
    "\n",
    "        for val in df_sorted[i]:\n",
    "            if len(df_sorted[df_sorted[i] == val]['y'].unique()) > 1:\n",
    "                y_ = df_sorted['y'].values\n",
    "                y_[df_sorted[i] == val] = cur_neg\n",
    "                df_sorted['y'] = y_\n",
    "                cur_neg -= 1\n",
    "        \n",
    "        tmp = df_sorted.rolling(2).apply(lambda x: x.iloc[1] - x.iloc[0])[1:].reset_index()\n",
    "        ids = tmp[(tmp.y != 0) & (tmp[i] != 0)]['index'].values\n",
    "        threshs.append((df_sorted.iloc[ids, i].values + df_sorted.iloc[ids-1, i].values) / 2)\n",
    "        threshs_raveled += list(threshs[-1])\n",
    "    return threshs, threshs_raveled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bool_matrix(df: pd.DataFrame, threshs, threshs_raveled):\n",
    "\n",
    "    unique_labels = sorted(df['y'].unique())\n",
    "    n_threshs = []\n",
    "    for i in range(len(threshs)):\n",
    "        n_threshs += [i] * len(threshs[i])\n",
    "    n_threshs += [-1]  # label\n",
    "\n",
    "    df_stretched = df.iloc[:, n_threshs]\n",
    "    classes = [df_stretched[df_stretched['y'] == y].drop(columns=['y']).values for y in unique_labels]\n",
    "    res = []\n",
    "    for c1, c2 in product(unique_labels, unique_labels):\n",
    "        if c1 >= c2:\n",
    "            continue\n",
    "        for row1, row2 in product(classes[c1], classes[c2]):\n",
    "            res.append(\n",
    "                (row1 <= threshs_raveled) & (row2 > threshs_raveled) | \\\n",
    "                (row1 > threshs_raveled) & (row2 <= threshs_raveled)\n",
    "            )\n",
    "    return pd.DataFrame(res, columns=df_stretched.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(df, threshs, column_names, recalibrate=True):\n",
    "    weights = []\n",
    "    for feature in df.columns:\n",
    "        if feature == 'y':\n",
    "            continue\n",
    "        feature_ts = [-np.inf] + threshs[feature].tolist() + [+np.inf]\n",
    "        obj = df[feature]\n",
    "        classes = df['y'].value_counts().sort_index()\n",
    "        w = []\n",
    "        N = []\n",
    "        \n",
    "        for i in range(1, len(feature_ts) - 1):\n",
    "            #left_class = df[(obj > feature_ts[i-1]) & (obj <= feature_ts[i])]['y'].value_counts(ascending=True).argmax()\n",
    "            #right_class = df[(obj < feature_ts[i+1]) & (obj >= feature_ts[i])]['y'].value_counts(ascending=True).argmax()\n",
    "            #assert left_class != right_class\n",
    "            NL = (obj > feature_ts[i-1]) & (obj <= feature_ts[i])\n",
    "            NR = (obj < feature_ts[i+1]) & (obj >= feature_ts[i])\n",
    "            NL_classes = df[NL]['y'].value_counts().sort_index()\n",
    "            NR_classes = df[NR]['y'].value_counts().sort_index()\n",
    "        \n",
    "            res = []\n",
    "        \n",
    "            for cls in NL_classes.index:\n",
    "                if cls not in NR_classes.index:\n",
    "                    NR_classes.at[cls] = 0\n",
    "            for cls in NR_classes.index:\n",
    "                if cls not in NL_classes.index:\n",
    "                    NL_classes.at[cls] = 0\n",
    "        \n",
    "            for cls1 in NL_classes.index:\n",
    "                for cls2 in NR_classes.index:\n",
    "                    if cls1 == cls2:\n",
    "                        continue\n",
    "                    KL = classes[cls1]\n",
    "                    KR = classes[cls2]\n",
    "                    left_n = (df[NL]['y'] == cls1).sum()\n",
    "                    right_n = (df[NR]['y'] == cls2).sum()\n",
    "                    c = abs(KR / (KR + KL) * left_n - KL / (KR + KL) * right_n)\n",
    "                    res.append(c)\n",
    "            w.append(np.mean(res))\n",
    "            \n",
    "            N.append(NL.sum())\n",
    "        N.append(NR.sum())\n",
    "        \n",
    "        assert sum(N) == df.shape[0]\n",
    "        assert 0 not in N\n",
    "        assert len(w) + 1 == len(N)\n",
    "\n",
    "        weights.append(np.array(w))\n",
    "\n",
    "    # recalibrate\n",
    "    if recalibrate:\n",
    "        means = [w.mean() for w in weights]\n",
    "        mu = np.mean(means)\n",
    "        weights = [w * (mu / w.mean()) for w in weights]\n",
    "\n",
    "    res = []\n",
    "    for elem in weights:\n",
    "        res += elem.tolist()\n",
    "    res = np.array(res)\n",
    "\n",
    "    temp = pd.DataFrame(res.reshape(1, -1))\n",
    "    temp.columns = column_names\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_df(M, cols, df, thresh, threshs_raveled, train=True):\n",
    "    features_threshs = {}\n",
    "    for c in cols:\n",
    "        feature = M.columns[c]\n",
    "        if feature not in features_threshs:\n",
    "            features_threshs[feature] = []\n",
    "        features_threshs[feature].append(threshs_raveled[c])\n",
    "    \n",
    "    df_ = {}\n",
    "    for feature in M.columns:\n",
    "        all_t = [-np.inf] + features_threshs[feature] + [+np.inf]\n",
    "        feature_copy = df[feature].values.copy()\n",
    "        for t_idx in range(1, len(all_t)):\n",
    "            cond = (df[feature] > all_t[t_idx - 1]) & (df[feature] < all_t[t_idx])\n",
    "            feature_copy[cond] = t_idx - 1\n",
    "        df_[feature] = feature_copy\n",
    "        if train:\n",
    "            assert len(np.unique(feature_copy)) == len(features_threshs[feature]) + 1, feature\n",
    "    df_['y'] = df['y'].copy()\n",
    "    df_ = pd.DataFrame(df_)\n",
    "\n",
    "    return df_.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2    3    4        5    6    7  y\n",
       "0    3.0  0.0  22.0  1.0  0.0   7.2500  0.0  0.0  0\n",
       "1    1.0  1.0  38.0  1.0  0.0  71.2833  1.0  1.0  1\n",
       "2    3.0  1.0  26.0  0.0  0.0   7.9250  0.0  0.0  1\n",
       "3    1.0  1.0  35.0  1.0  0.0  53.1000  1.0  0.0  1\n",
       "4    3.0  0.0  35.0  0.0  0.0   8.0500  0.0  0.0  0\n",
       "..   ...  ...   ...  ...  ...      ...  ...  ... ..\n",
       "883  3.0  1.0  39.0  0.0  5.0  29.1250  0.0  2.0  0\n",
       "885  1.0  1.0  19.0  0.0  0.0  30.0000  6.0  0.0  1\n",
       "886  3.0  1.0  28.0  1.0  2.0  23.4500  0.0  0.0  0\n",
       "887  1.0  0.0  26.0  0.0  0.0  30.0000  1.0  1.0  1\n",
       "888  3.0  0.0  32.0  0.0  0.0   7.7500  0.0  2.0  0\n",
       "\n",
       "[765 rows x 9 columns]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_filename = \"../../data/Titanic/cleaned.csv\"\n",
    "df = pd.read_csv(dataset_filename)\n",
    "\n",
    "y = df.y\n",
    "df = pd.DataFrame(df.drop(columns=['y']).values)\n",
    "df['y'] = y.values\n",
    "\n",
    "df.drop_duplicates(inplace=True, subset=list(range(df.shape[1] - 1)))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "X, y = data.drop(columns=['y']).values, data['y'].values\n",
    "kf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th fold, accuracy 0.64\n",
      "1th fold, accuracy 0.68\n",
      "2th fold, accuracy 0.72\n",
      "3th fold, accuracy 0.8\n",
      "4th fold, accuracy 0.6\n",
      "5th fold, accuracy 0.64\n",
      "6th fold, accuracy 0.88\n",
      "7th fold, accuracy 0.76\n",
      "8th fold, accuracy 0.64\n",
      "9th fold, accuracy 0.8\n",
      "0.716\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    #print(y_hat.sum())\n",
    "    \n",
    "    acc = (y_hat == y_test).sum() / len(y_test)\n",
    "    print(f\"{i}th fold, accuracy {acc}\")\n",
    "    accs.append(acc)\n",
    "\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs, threshs_raveled = compute_thresholds(df)\n",
    "M = gen_bool_matrix(df, threshs, threshs_raveled)\n",
    "assert M.sum(axis=1).min() >= 1\n",
    "M.astype(int).to_csv('./data/bool.csv', index=False)\n",
    "weights = get_weights(df, threshs, M.columns, recalibrate=True)\n",
    "weights.to_csv('./data/ranks.csv', index=False, header=False)\n",
    "call([\"./GeneticAlgorithm.o\", str(M.shape[0]), str(M.shape[1]), \"elementwise\", \"maxbinsnum\"])\n",
    "with open(\"./data/results.txt\", 'r') as file:\n",
    "    cols = list(map(int, file.readline().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_method(filename, rank_function, fitness_function, n_folds, recalibrate=True, sample=None, random_state=42):\n",
    "    df = pd.read_csv(filename)\n",
    "    y = df.y\n",
    "    df = pd.DataFrame(df.drop(columns=['y']).values)\n",
    "    df['y'] = y.values\n",
    "    df.drop_duplicates(inplace=True, subset=list(range(df.shape[1] - 1)))\n",
    "    if sample:\n",
    "        df = df.sample(sample, random_state=random_state)\n",
    "    y = df['y']\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "    accs = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(df, y.values)):\n",
    "        df_train, df_test = df.iloc[train_index].reset_index(drop='index'), df.iloc[test_index].reset_index(drop='index')\n",
    "\n",
    "        threshs, threshs_raveled = compute_thresholds(df_train)\n",
    "        M = gen_bool_matrix(df_train, threshs, threshs_raveled)\n",
    "        assert M.sum(axis=1).min() >= 1\n",
    "        M.astype(int).to_csv('./data/bool.csv', index=False)\n",
    "        weights = get_weights(df_train, threshs, M.columns, recalibrate=recalibrate)\n",
    "        weights.to_csv('./data/ranks.csv', index=False, header=False)\n",
    "\n",
    "        call([\"./GeneticAlgorithm.o\", str(M.shape[0]), str(M.shape[1]), rank_function, fitness_function])\n",
    "        with open(\"./data/results.txt\", 'r') as file:\n",
    "            cols = list(map(int, file.readline().split()))\n",
    "\n",
    "        df_train = get_encoded_df(M, cols, df_train, threshs, threshs_raveled, train=True)\n",
    "        df_test = get_encoded_df(M, cols, df_test, threshs, threshs_raveled, train=False)\n",
    "        X_train, y_train = df_train.drop(columns=['y']).values, df_train['y'].values\n",
    "        X_test, y_test = df_test.drop(columns=['y']).values, df_test['y'].values\n",
    "\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "        acc = (y_hat == y_test).sum() / len(y_test)\n",
    "        print(f\"{i}th fold, accuracy {acc}\")\n",
    "        accs.append(acc)\n",
    "\n",
    "    print(f\"Mean accuracy {np.mean(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th fold, accuracy 0.64\n",
      "1th fold, accuracy 0.72\n",
      "2th fold, accuracy 0.76\n",
      "3th fold, accuracy 0.84\n",
      "4th fold, accuracy 0.6\n",
      "5th fold, accuracy 0.64\n",
      "6th fold, accuracy 0.84\n",
      "7th fold, accuracy 0.84\n",
      "8th fold, accuracy 0.56\n",
      "9th fold, accuracy 0.76\n",
      "Mean accuracy 0.72\n"
     ]
    }
   ],
   "source": [
    "test_method(\n",
    "    filename=\"../../data/Titanic/cleaned.csv\",\n",
    "    rank_function=\"elementwise\",\n",
    "    fitness_function=\"maxbinsnum\",\n",
    "    n_folds=10,\n",
    "    recalibrate=True,\n",
    "    sample=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th fold, accuracy 0.56\n",
      "1th fold, accuracy 0.72\n",
      "2th fold, accuracy 0.84\n",
      "3th fold, accuracy 0.84\n",
      "4th fold, accuracy 0.6\n",
      "5th fold, accuracy 0.72\n",
      "6th fold, accuracy 0.88\n",
      "7th fold, accuracy 0.8\n",
      "8th fold, accuracy 0.56\n",
      "9th fold, accuracy 0.68\n",
      "Mean accuracy 0.72\n"
     ]
    }
   ],
   "source": [
    "test_method(\n",
    "    filename=\"../../data/Titanic/cleaned.csv\",\n",
    "    rank_function=\"groupwise\",\n",
    "    fitness_function=\"maxbinsnum\",\n",
    "    n_folds=10,\n",
    "    recalibrate=True,\n",
    "    sample=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
