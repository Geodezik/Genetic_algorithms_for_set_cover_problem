{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from time import time\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thresholds(df):\n",
    "    threshs = []\n",
    "    threshs_raveled = []\n",
    "    cur_neg = -1\n",
    "    for i in range(df.shape[1] - 1):\n",
    "        df_sorted = df.sort_values(by=i).reset_index(drop='index')\n",
    "\n",
    "        for val in df_sorted[i]:\n",
    "            if len(df_sorted[df_sorted[i] == val]['y'].unique()) > 1:\n",
    "                y_ = df_sorted['y'].values\n",
    "                y_[df_sorted[i] == val] = cur_neg\n",
    "                df_sorted['y'] = y_\n",
    "                cur_neg -= 1\n",
    "        \n",
    "        tmp = df_sorted.rolling(2).apply(lambda x: x.iloc[1] - x.iloc[0])[1:].reset_index()\n",
    "        ids = tmp[(tmp.y != 0) & (tmp[i] != 0)]['index'].values\n",
    "        threshs.append((df_sorted.iloc[ids, i].values + df_sorted.iloc[ids-1, i].values) / 2)\n",
    "        threshs_raveled += list(threshs[-1])\n",
    "\n",
    "    return threshs, threshs_raveled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bool_matrix(df: pd.DataFrame, threshs, threshs_raveled):\n",
    "\n",
    "    unique_labels = sorted(df['y'].unique())\n",
    "    n_threshs = []\n",
    "    for i in range(len(threshs)):\n",
    "        n_threshs += [i] * len(threshs[i])\n",
    "    n_threshs += [-1]  # label\n",
    "\n",
    "    df_stretched = df.iloc[:, n_threshs]\n",
    "    classes = [df_stretched[df_stretched['y'] == y].drop(columns=['y']).values for y in unique_labels]\n",
    "    res = []\n",
    "    for c1, c2 in product(unique_labels, unique_labels):\n",
    "        if c1 >= c2:\n",
    "            continue\n",
    "        for row1, row2 in product(classes[c1], classes[c2]):\n",
    "            res.append(\n",
    "                (row1 <= threshs_raveled) & (row2 > threshs_raveled) | \\\n",
    "                (row1 > threshs_raveled) & (row2 <= threshs_raveled)\n",
    "            )\n",
    "    return pd.DataFrame(res, columns=df_stretched.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(df, threshs, column_names, rank_formula=\"-\", recalibrate=True):\n",
    "    weights = []\n",
    "    for feature in df.columns:\n",
    "        if feature == 'y':\n",
    "            continue\n",
    "        feature_ts = [-np.inf] + threshs[feature].tolist() + [+np.inf]\n",
    "        obj = df[feature]\n",
    "        classes = df['y'].value_counts().sort_index()\n",
    "        w = []\n",
    "        N = []\n",
    "        \n",
    "        for i in range(1, len(feature_ts) - 1):\n",
    "            #left_class = df[(obj > feature_ts[i-1]) & (obj <= feature_ts[i])]['y'].value_counts(ascending=True).argmax()\n",
    "            #right_class = df[(obj < feature_ts[i+1]) & (obj >= feature_ts[i])]['y'].value_counts(ascending=True).argmax()\n",
    "            #assert left_class != right_class\n",
    "            NL = (obj > feature_ts[i-1]) & (obj <= feature_ts[i])\n",
    "            NR = (obj < feature_ts[i+1]) & (obj >= feature_ts[i])\n",
    "            NL_classes = df[NL]['y'].value_counts().sort_index()\n",
    "            NR_classes = df[NR]['y'].value_counts().sort_index()\n",
    "        \n",
    "            res = []\n",
    "        \n",
    "            for cls in NL_classes.index:\n",
    "                if cls not in NR_classes.index:\n",
    "                    NR_classes.at[cls] = 0\n",
    "            for cls in NR_classes.index:\n",
    "                if cls not in NL_classes.index:\n",
    "                    NL_classes.at[cls] = 0\n",
    "        \n",
    "            for cls1 in NL_classes.index:\n",
    "                for cls2 in NR_classes.index:\n",
    "                    if cls1 == cls2:\n",
    "                        continue\n",
    "                    KL = classes[cls1]\n",
    "                    KR = classes[cls2]\n",
    "                    left_n = (df[NL]['y'] == cls1).sum()\n",
    "                    right_n = (df[NR]['y'] == cls2).sum()\n",
    "                    if rank_formula == \"-\":\n",
    "                        c = abs(KR / (KR + KL) * left_n - KL / (KR + KL) * right_n)\n",
    "                    elif rank_formula == \"+\":\n",
    "                        c = -abs(KR / (KR + KL) * left_n + KL / (KR + KL) * right_n)\n",
    "                    elif rank_formula == \"anti+\":\n",
    "                        c = abs(KR / (KR + KL) * left_n + KL / (KR + KL) * right_n)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                    res.append(c)\n",
    "            w.append(np.mean(res))\n",
    "            \n",
    "            N.append(NL.sum())\n",
    "        N.append(NR.sum())\n",
    "        \n",
    "        assert sum(N) == df.shape[0], len(threshs[feature])\n",
    "        assert 0 not in N\n",
    "        assert len(w) + 1 == len(N)\n",
    "\n",
    "        weights.append(np.array(w))\n",
    "\n",
    "    # recalibrate\n",
    "    if recalibrate:\n",
    "        means = [w.mean() for w in weights]\n",
    "        mu = np.mean(means)\n",
    "        weights = [w * (mu / w.mean()) for w in weights]\n",
    "\n",
    "    res = []\n",
    "    for elem in weights:\n",
    "        res += elem.tolist()\n",
    "    res = np.array(res)\n",
    "\n",
    "    temp = pd.DataFrame(res.reshape(1, -1))\n",
    "    temp.columns = column_names\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_df(M, cols, df, thresh, threshs_raveled, train=True):\n",
    "    features_threshs = {}\n",
    "    for c in cols:\n",
    "        feature = M.columns[c]\n",
    "        if feature not in features_threshs:\n",
    "            features_threshs[feature] = []\n",
    "        features_threshs[feature].append(threshs_raveled[c])\n",
    "    \n",
    "    df_ = {}\n",
    "    for feature in M.columns:\n",
    "        all_t = [-np.inf] + features_threshs[feature] + [+np.inf]\n",
    "        feature_copy = df[feature].values.copy()\n",
    "        for t_idx in range(1, len(all_t)):\n",
    "            cond = (df[feature] > all_t[t_idx - 1]) & (df[feature] <= all_t[t_idx])\n",
    "            feature_copy[cond] = t_idx - 1\n",
    "        df_[feature] = feature_copy\n",
    "        if train:\n",
    "            assert len(np.unique(feature_copy)) == len(features_threshs[feature]) + 1, feature\n",
    "    df_['y'] = df['y'].copy()\n",
    "    df_ = pd.DataFrame(df_)\n",
    "\n",
    "    return df_.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_nums(df, threshs=None):\n",
    "    df = df.copy()\n",
    "    num = [c for c in df.columns if df[c].dtype == float]\n",
    "    threshs_ = []\n",
    "    for i, feature in enumerate(num):\n",
    "        if threshs:\n",
    "            all_t = threshs[i]\n",
    "        else:\n",
    "            all_t = [-np.inf] + np.unique(np.sort(df[feature].values)).tolist()[:-1] + [+np.inf]\n",
    "            threshs_.append(all_t)\n",
    "        feature_copy = df[feature].values.copy().astype(int)\n",
    "        for t_idx in range(1, len(all_t)):\n",
    "            cond = (df[feature] > all_t[t_idx - 1]) & (df[feature] <= all_t[t_idx])\n",
    "            feature_copy[cond] = t_idx - 1\n",
    "        df[feature] = feature_copy\n",
    "    if threshs is None:\n",
    "        return df, threshs_\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_test(filename, n_splits=5, sample=None):\n",
    "    df = pd.read_csv(filename)\n",
    "    y = df.y\n",
    "    df = pd.DataFrame(df.drop(columns=['y']).values)\n",
    "    df['y'] = y.values\n",
    "    df.drop_duplicates(inplace=True, subset=list(range(df.shape[1] - 1)))\n",
    "\n",
    "    if sample:\n",
    "        df = df.sample(min(sample, len(df)), random_state=42)\n",
    "\n",
    "    data = df\n",
    "    X, y = data.drop(columns=['y']).values, data['y'].values\n",
    "    kf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "        model = RandomForestClassifier(500, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "        #print(y_hat.sum())\n",
    "        \n",
    "        acc = (y_hat == y_test).sum() / len(y_test)\n",
    "        print(f\"{i}th fold, accuracy {acc}\")\n",
    "        accs.append(acc)\n",
    "\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th fold, accuracy 0.6176470588235294\n",
      "1th fold, accuracy 0.5454545454545454\n",
      "2th fold, accuracy 0.7878787878787878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6503267973856209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test('../data/Titanic/cleaned.csv', sample=100, n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_method(filename, algorithm, n_iter, noiter_frac, alpha, rank_function, fitness_function, n_folds, p=None, encode=False, rank_formula=\"-\", recalibrate=True, sample=None, random_state=42):\n",
    "    def clean():\n",
    "        files = ['scores_0_pred.txt', 'scores_0_irr.txt']\n",
    "        for f in files:\n",
    "            if f in os.listdir(\"./data\"):\n",
    "                os.remove(f\"./data/{f}\")\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    df = pd.read_csv(filename)\n",
    "    y = df.y\n",
    "    df = pd.DataFrame(df.drop(columns=['y']).values)\n",
    "    df['y'] = y.values\n",
    "    df.drop_duplicates(inplace=True, subset=list(range(df.shape[1] - 1)))\n",
    "    if sample:\n",
    "        df = df.sample(min(sample, len(df)), random_state=42) # ALWAYS 42!!!!!!!!!\n",
    "    print(f\"Df shape: {df.shape}\")\n",
    "    y = df['y']\n",
    "    all_c = np.unique(y)\n",
    "    binary = (len(all_c) == 2)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "    accs = {'irr': [], 'pred': []}\n",
    "    times = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(df, y.values)):\n",
    "        seed = np.random.randint(0, 1e6)\n",
    "        df_train, df_test = df.iloc[train_index].reset_index(drop='index').copy(), df.iloc[test_index].reset_index(drop='index').copy()\n",
    "\n",
    "        assert df_train.nunique().min() > 1\n",
    "\n",
    "        if encode:\n",
    "            threshs, threshs_raveled = compute_thresholds(df_train)\n",
    "            M = gen_bool_matrix(df_train, threshs, threshs_raveled)\n",
    "            assert M.sum(axis=1).min() >= 1\n",
    "            M.astype(int).to_csv('./data/bool.csv', index=False)\n",
    "            weights = get_weights(df_train, threshs, M.columns, rank_formula=rank_formula, recalibrate=recalibrate)\n",
    "            weights.to_csv('./data/ranks.csv', index=False, header=False)\n",
    "\n",
    "            t = time()\n",
    "            call([\"./CorrectEncoding.o\", str(seed), str(M.shape[0]), str(M.shape[1]), str(n_iter), str(noiter_frac), str(alpha), rank_function, fitness_function, algorithm])\n",
    "            t = time() - t\n",
    "            with open(\"./data/results.txt\", 'r') as file:\n",
    "                cols = list(map(int, file.readline().split()))\n",
    "\n",
    "            df_train = get_encoded_df(M, cols, df_train, threshs, threshs_raveled, train=True)\n",
    "            df_test = get_encoded_df(M, cols, df_test, threshs, threshs_raveled, train=False)\n",
    "        \n",
    "        else:\n",
    "            t = 0.0\n",
    "            df_train, enc_threshs = encode_nums(df_train)\n",
    "            df_test = encode_nums(df_test, enc_threshs)\n",
    "        times.append(t)\n",
    "\n",
    "        X_train, y_train = df_train.drop(columns=['y']).values, df_train['y'].values\n",
    "        X_test, y_test = df_test.drop(columns=['y']).values, df_test['y'].values\n",
    "\n",
    "        enc = OneHotEncoder()\n",
    "        X_train = enc.fit_transform(X_train).toarray().astype(int)\n",
    "        X_test = enc.transform(X_test).toarray().astype(int)\n",
    "\n",
    "        if binary and False:\n",
    "            # perform binary one-run classification\n",
    "\n",
    "            X_k = pd.DataFrame(X_train[y_train == 1])\n",
    "            X_no = pd.DataFrame(X_train[y_train == 0])\n",
    "            X_te = pd.DataFrame(X_train)\n",
    "            X_k.to_csv('./data/X_k.txt', index=False, header=False, sep=' ')\n",
    "            X_no.to_csv('./data/X_no.txt', index=False, header=False, sep=' ')\n",
    "            X_te.to_csv('./data/X_test.txt', index=False, header=False, sep=' ')\n",
    "\n",
    "            clean()\n",
    "            if p is None:\n",
    "                m, n = X_k.shape[0], X_k.shape[1]\n",
    "                p_ = round(0.5 * np.log2(m * n) - 0.5 * np.log2(np.log2(m * n)) - np.log2(np.log2(np.log2(n))))\n",
    "                p_ = 1 if (p_ <= 0) else p_\n",
    "            else:\n",
    "                p_ = p\n",
    "            call([\"./ADR.o\", str(p_)])\n",
    "\n",
    "            for classifier in ['irr', 'pred']:\n",
    "                with open(f\"./data/scores_0_{classifier}.txt\") as f:\n",
    "                    votes = list(map(float, f.read().strip().split(' | ')[-1].split()))\n",
    "                #assert len(votes) == len(X_test)\n",
    "\n",
    "                votes = np.array(votes)\n",
    "                y_pred = (votes > 0.0)\n",
    "                accs[classifier].append((y_pred == y_train).mean())\n",
    "\n",
    "        else:\n",
    "            # perform one-vs-all classification\n",
    "\n",
    "            votes = {'irr': [], 'pred': []}\n",
    "            for c in all_c:\n",
    "                X_k = pd.DataFrame(X_train[y_train == c])\n",
    "                X_no = pd.DataFrame(X_train[y_train != c])\n",
    "                X_te = pd.DataFrame(X_test)\n",
    "                X_k.to_csv('./data/X_k.txt', index=False, header=False, sep=' ')\n",
    "                X_no.to_csv('./data/X_no.txt', index=False, header=False, sep=' ')\n",
    "                X_te.to_csv('./data/X_test.txt', index=False, header=False, sep=' ')\n",
    "\n",
    "                clean()\n",
    "                if p is None:\n",
    "                    m, n = X_k.shape[0], X_k.shape[1]\n",
    "                    p_ = round(0.5 * np.log2(m * n) - 0.5 * np.log2(np.log2(m * n)) - np.log2(np.log2(np.log2(n))))\n",
    "                    p_ = 1 if (p_ <= 0) else p_\n",
    "                else:\n",
    "                    p_ = p\n",
    "                call([\"./ADR.o\", str(p_)])\n",
    "\n",
    "                for classifier in ['irr', 'pred']:\n",
    "                    with open(f\"./data/scores_0_{classifier}.txt\") as f:\n",
    "                        votes[classifier].append(list(map(float, f.read().strip().split(' | ')[-1].split())))\n",
    "                    assert len(votes[classifier][-1]) == len(X_test)\n",
    "\n",
    "            for classifier in ['irr', 'pred']:\n",
    "                votes[classifier] = np.array(votes[classifier])\n",
    "                y_pred = votes[classifier].argmax(axis=0)\n",
    "                accs[classifier].append((y_pred == y_test).mean())\n",
    "    \n",
    "    return times, accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./CorrectEncoding.o 42 90932 245 250 2 0.5 elementwise maxbinsnum gencode+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (147, 5)\n",
      "(4562, 48)\n",
      "(4562, 54)\n",
      "(4640, 54)\n",
      "(4641, 53)\n",
      "(4641, 54)\n"
     ]
    }
   ],
   "source": [
    "    times, accs = test_method(\n",
    "        filename=f'../data/Iris/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']\n",
    "\n",
    "Whole data, no encoding\n",
    "\n",
    "[(0.6052515201768933, 0.6141293532338308),\n",
    " (0.26, 0.26),\n",
    " (0.4807317073170731, 0.7645121951219512),\n",
    " (0.3207164179104478, 0.3675273631840796),\n",
    " (0.3264367816091954, 0.3264367816091954),\n",
    " (0.5947712418300654, 0.6941176470588235)]\n",
    "\n",
    " Greedy encoding\n",
    "\n",
    " [(0.6334549474847984, 0.6349143173023769),\n",
    " (0.472, 0.56),\n",
    " (0.8184146341463416, 0.8042682926829269),\n",
    " (0.6842985074626865, 0.7311194029850745),\n",
    " (0.8372413793103448, 0.9386206896551723),\n",
    " (0.6797385620915033, 0.7908496732026143)]\n",
    "\n",
    " CODE3\n",
    "\n",
    " [(0.6393587617468215, 0.6453067993366501),\n",
    " (0.6120000000000001, 0.6200000000000001),\n",
    " (0.7748780487804878, 0.7796341463414634),\n",
    " (0.6782935323383084, 0.7231094527363184),\n",
    " (0.7475862068965518, 0.9048275862068966),\n",
    " (0.6784313725490196, 0.7594771241830065)]\n",
    "\n",
    " GENCODE+\n",
    "\n",
    " [(0.6349364289662798, 0.6660917634051963),\n",
    " (0.6040000000000001, 0.6120000000000001),\n",
    " (0.8482926829268294, 0.8631707317073172),\n",
    " (0.6673781094527363, 0.7241293532338309),\n",
    " (0.8622988505747127, 0.9312643678160919), # fake\n",
    " (0.673202614379085, 0.7856209150326798)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 1.3010878086090087 all_accs (0.6334549474847984, 0.6349143173023769)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 1.244109296798706 all_accs (0.472, 0.56)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.31728811264038087 all_accs (0.8184146341463416, 0.8042682926829269)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 42.021964359283444 all_accs (0.6842985074626865, 0.7311194029850745)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.04492635726928711 all_accs (0.8372413793103448, 0.9386206896551723)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 5.652727699279785 all_accs (0.6797385620915033, 0.7908496732026143)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='greedy',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.3010878086090087,\n",
       "  1.244109296798706,\n",
       "  0.31728811264038087,\n",
       "  42.021964359283444,\n",
       "  0.04492635726928711,\n",
       "  5.652727699279785],\n",
       " [(0.6334549474847984, 0.6349143173023769),\n",
       "  (0.472, 0.56),\n",
       "  (0.8184146341463416, 0.8042682926829269),\n",
       "  (0.6842985074626865, 0.7311194029850745),\n",
       "  (0.8372413793103448, 0.9386206896551723),\n",
       "  (0.6797385620915033, 0.7908496732026143)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 9.340883111953735 all_accs (0.6394140409065783, 0.654228855721393)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 4.681877660751343 all_accs (0.524, 0.5559999999999999)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 1.066990041732788 all_accs (0.7942682926829268, 0.8285365853658536)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 172.34560232162477 all_accs (0.6583930348258706, 0.7002487562189055)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.21153702735900878 all_accs (0.7193103448275862, 0.7813793103448277)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 23.173298931121828 all_accs (0.677124183006536, 0.776470588235294)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='code3',\n",
    "        n_iter=500, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9.340883111953735,\n",
       "  4.681877660751343,\n",
       "  1.066990041732788,\n",
       "  172.34560232162477,\n",
       "  0.21153702735900878,\n",
       "  23.173298931121828],\n",
       " [(0.6394140409065783, 0.654228855721393),\n",
       "  (0.524, 0.5559999999999999),\n",
       "  (0.7942682926829268, 0.8285365853658536),\n",
       "  (0.6583930348258706, 0.7002487562189055),\n",
       "  (0.7193103448275862, 0.7813793103448277),\n",
       "  (0.677124183006536, 0.776470588235294)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.45449275970459 all_accs (0.6246213377556661, 0.6379657269209509)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.5882005214691164 all_accs (0.548, 0.548)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.6235669612884521 all_accs (0.77, 0.7746341463414634)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 76.6169870853424 all_accs (0.6902885572139305, 0.7311293532338309)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.13288440704345703 all_accs (0.8289655172413793, 0.8698850574712644)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 11.446849918365478 all_accs (0.6718954248366013, 0.776470588235294)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.45449275970459,\n",
       "  2.5882005214691164,\n",
       "  0.6235669612884521,\n",
       "  76.6169870853424,\n",
       "  0.13288440704345703,\n",
       "  11.446849918365478],\n",
       " [(0.6246213377556661, 0.6379657269209509),\n",
       "  (0.548, 0.548),\n",
       "  (0.77, 0.7746341463414634),\n",
       "  (0.6902885572139305, 0.7311293532338309),\n",
       "  (0.8289655172413793, 0.8698850574712644),\n",
       "  (0.6718954248366013, 0.776470588235294)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.525192165374756 all_accs (0.636506357103372, 0.6408734107241569)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.000855827331543 all_accs (0.5800000000000001, 0.5800000000000001)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.5133427143096924 all_accs (0.808658536585366, 0.8384146341463413)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 55.15505781173706 all_accs (0.6842885572139303, 0.7141542288557214)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.1390974998474121 all_accs (0.8694252873563219, 0.9314942528735631)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 10.239969444274902 all_accs (0.6797385620915033, 0.7790849673202614)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.525192165374756,\n",
       "  2.000855827331543,\n",
       "  0.5133427143096924,\n",
       "  55.15505781173706,\n",
       "  0.1390974998474121,\n",
       "  10.239969444274902],\n",
       " [(0.636506357103372, 0.6408734107241569),\n",
       "  (0.5800000000000001, 0.5800000000000001),\n",
       "  (0.808658536585366, 0.8384146341463413),\n",
       "  (0.6842885572139303, 0.7141542288557214),\n",
       "  (0.8694252873563219, 0.9314942528735631),\n",
       "  (0.6797385620915033, 0.7790849673202614)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.7061420440673825 all_accs (0.6305583195135434, 0.6557324488667773)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 1.9709696292877197 all_accs (0.532, 0.532)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.4903904438018799 all_accs (0.7990243902439025, 0.8189024390243901)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 61.78007264137268 all_accs (0.6574228855721393, 0.6962437810945274)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.1283331871032715 all_accs (0.8910344827586207, 0.9183908045977013)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 10.319379901885986 all_accs (0.6732026143790849, 0.7843137254901962)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=False,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.7061420440673825,\n",
       "  1.9709696292877197,\n",
       "  0.4903904438018799,\n",
       "  61.78007264137268,\n",
       "  0.1283331871032715,\n",
       "  10.319379901885986],\n",
       " [(0.6305583195135434, 0.6557324488667773),\n",
       "  (0.532, 0.532),\n",
       "  (0.7990243902439025, 0.8189024390243901),\n",
       "  (0.6574228855721393, 0.6962437810945274),\n",
       "  (0.8910344827586207, 0.9183908045977013),\n",
       "  (0.6732026143790849, 0.7843137254901962)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.8019242763519285 all_accs (0.6290547263681592, 0.6483250414593698)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.344622802734375 all_accs (0.5760000000000001, 0.5760000000000001)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.5771588325500489 all_accs (0.8240243902439024, 0.809390243902439)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 66.74905843734741 all_accs (0.6395174129353233, 0.6953134328358209)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.15609617233276368 all_accs (0.8556321839080461, 0.9245977011494253)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 13.857624816894532 all_accs (0.6679738562091504, 0.7803921568627451)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='groupwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=False,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.8019242763519285,\n",
       "  2.344622802734375,\n",
       "  0.5771588325500489,\n",
       "  66.74905843734741,\n",
       "  0.15609617233276368,\n",
       "  13.857624816894532],\n",
       " [(0.6290547263681592, 0.6483250414593698),\n",
       "  (0.5760000000000001, 0.5760000000000001),\n",
       "  (0.8240243902439024, 0.809390243902439),\n",
       "  (0.6395174129353233, 0.6953134328358209),\n",
       "  (0.8556321839080461, 0.9245977011494253),\n",
       "  (0.6679738562091504, 0.7803921568627451)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 5.554165172576904 all_accs (0.6498728579325593, 0.6527805417357657)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.349442720413208 all_accs (0.532, 0.52)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.6046135425567627 all_accs (0.7796341463414633, 0.8335365853658537)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 72.94669871330261 all_accs (0.6643880597014925, 0.7231094527363184)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.15090174674987794 all_accs (0.8696551724137931, 0.9317241379310344)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 13.430852127075195 all_accs (0.673202614379085, 0.7790849673202614)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='groupwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"+\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5.554165172576904,\n",
       "  2.349442720413208,\n",
       "  0.6046135425567627,\n",
       "  72.94669871330261,\n",
       "  0.15090174674987794,\n",
       "  13.430852127075195],\n",
       " [(0.6498728579325593, 0.6527805417357657),\n",
       "  (0.532, 0.52),\n",
       "  (0.7796341463414633, 0.8335365853658537),\n",
       "  (0.6643880597014925, 0.7231094527363184),\n",
       "  (0.8696551724137931, 0.9317241379310344),\n",
       "  (0.673202614379085, 0.7790849673202614)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 5.278198528289795 all_accs (0.6349364289662798, 0.6660917634051963)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.275641345977783 all_accs (0.6040000000000001, 0.6120000000000001)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.5580727100372315 all_accs (0.8482926829268294, 0.8631707317073172)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 69.15301852226257 all_accs (0.6673781094527363, 0.7241293532338309)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.14617457389831542 all_accs (0.8351724137931035, 0.8351724137931035)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 12.732571363449097 all_accs (0.673202614379085, 0.7856209150326798)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"-\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5.278198528289795,\n",
       "  2.275641345977783,\n",
       "  0.5580727100372315,\n",
       "  69.15301852226257,\n",
       "  0.14617457389831542,\n",
       "  12.732571363449097],\n",
       " [(0.6349364289662798, 0.6660917634051963),\n",
       "  (0.6040000000000001, 0.6120000000000001),\n",
       "  (0.8482926829268294, 0.8631707317073172),\n",
       "  (0.6673781094527363, 0.7241293532338309),\n",
       "  (0.8351724137931035, 0.8351724137931035),\n",
       "  (0.673202614379085, 0.7856209150326798)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.568147802352906 all_accs (0.6394140409065783, 0.6498065229408512)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.079791450500488 all_accs (0.556, 0.556)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.5154966354370117 all_accs (0.8184146341463416, 0.833780487804878)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 57.329112434387206 all_accs (0.6494378109452736, 0.6962686567164179)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.13687868118286134 all_accs (0.8289655172413793, 0.8289655172413793)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 10.946486282348634 all_accs (0.6745098039215687, 0.7843137254901961)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='elementwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"-\",\n",
    "        recalibrate=False,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.568147802352906,\n",
       "  2.079791450500488,\n",
       "  0.5154966354370117,\n",
       "  57.329112434387206,\n",
       "  0.13687868118286134,\n",
       "  10.946486282348634],\n",
       " [(0.6394140409065783, 0.6498065229408512),\n",
       "  (0.556, 0.556),\n",
       "  (0.8184146341463416, 0.833780487804878),\n",
       "  (0.6494378109452736, 0.6962686567164179),\n",
       "  (0.8289655172413793, 0.8289655172413793),\n",
       "  (0.6745098039215687, 0.7843137254901961)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.535551309585571 all_accs (0.6453067993366501, 0.6467993366500829)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.1001484870910643 all_accs (0.62, 0.6279999999999999)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.5218067646026612 all_accs (0.8140243902439025, 0.8285365853658536)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 66.36536836624146 all_accs (0.6553781094527362, 0.7041940298507463)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.13694353103637696 all_accs (0.890574712643678, 0.890574712643678)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 10.99763526916504 all_accs (0.681045751633987, 0.7856209150326797)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='groupwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"-\",\n",
    "        recalibrate=False,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.535551309585571,\n",
       "  2.1001484870910643,\n",
       "  0.5218067646026612,\n",
       "  66.36536836624146,\n",
       "  0.13694353103637696,\n",
       "  10.99763526916504],\n",
       " [(0.6453067993366501, 0.6467993366500829),\n",
       "  (0.62, 0.6279999999999999),\n",
       "  (0.8140243902439025, 0.8285365853658536),\n",
       "  (0.6553781094527362, 0.7041940298507463),\n",
       "  (0.890574712643678, 0.890574712643678),\n",
       "  (0.681045751633987, 0.7856209150326797)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (674, 19)\n",
      "Task Medicine, avg_time 4.510274362564087 all_accs (0.6468546158098397, 0.6453731343283582)\n",
      "Df shape: (250, 15)\n",
      "Task Music, avg_time 2.064577913284302 all_accs (0.588, 0.588)\n",
      "Df shape: (204, 23)\n",
      "Task Cars, avg_time 0.5179290294647216 all_accs (0.7991463414634147, 0.8434146341463415)\n",
      "Df shape: (1004, 12)\n",
      "Task Cameras, avg_time 81.58032422065735 all_accs (0.6454577114427861, 0.7101990049751243)\n",
      "Df shape: (147, 5)\n",
      "Task Iris, avg_time 0.16032109260559083 all_accs (0.8974712643678162, 0.9319540229885057)\n",
      "Df shape: (765, 9)\n",
      "Task Titanic, avg_time 13.144987726211548 all_accs (0.6745098039215687, 0.7869281045751634)\n"
     ]
    }
   ],
   "source": [
    "all_times, all_accs = [], []\n",
    "for task in ['Medicine', 'Music', 'Cars', 'Cameras', 'Iris', 'Titanic']:\n",
    "    times, accs = test_method(\n",
    "        filename=f'../data/{task}/cleaned.csv',\n",
    "        algorithm='gencode+',\n",
    "        n_iter=250, \n",
    "        noiter_frac=2,\n",
    "        alpha=0.5,\n",
    "        rank_function='groupwise',\n",
    "        fitness_function='maxbinsnum',\n",
    "        n_folds=5,\n",
    "        p=None,\n",
    "        encode=True,\n",
    "        rank_formula=\"-\",\n",
    "        recalibrate=True,\n",
    "        sample=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    all_times.append(np.mean(times))\n",
    "    all_accs.append((np.mean(accs['irr']), np.mean(accs['pred'])))\n",
    "    print(f\"Task {task}, avg_time {all_times[-1]} all_accs {all_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.510274362564087,\n",
       "  2.064577913284302,\n",
       "  0.5179290294647216,\n",
       "  81.58032422065735,\n",
       "  0.16032109260559083,\n",
       "  13.144987726211548],\n",
       " [(0.6468546158098397, 0.6453731343283582),\n",
       "  (0.588, 0.588),\n",
       "  (0.7991463414634147, 0.8434146341463415),\n",
       "  (0.6454577114427861, 0.7101990049751243),\n",
       "  (0.8974712643678162, 0.9319540229885057),\n",
       "  (0.6745098039215687, 0.7869281045751634)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_times, all_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
